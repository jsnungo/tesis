{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QLjmjOaUx3bF"},"outputs":[],"source":["!pip install tensorboardX\n","!pip install torchnet\n","!pip install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1009,"status":"ok","timestamp":1711203666752,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"YgirIlyvyB20","outputId":"57821606-1092-406c-83d3-166b1788fc35"},"outputs":[],"source":["import os\n","colab = False\n","\n","if colab:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    os.chdir('/content/drive/MyDrive/Tesis/tesis/classificador')\n","else:\n","    os.chdir('../classificador')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7341,"status":"ok","timestamp":1711203674970,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"Jczl06_MyG_i"},"outputs":[],"source":["import time\n","\n","from tqdm import *\n","\n","import torch\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torch.utils.data.sampler import WeightedRandomSampler\n","\n","import torchvision\n","from torchvision.transforms import *\n","\n","from tensorboardX import SummaryWriter\n","\n","import models\n","from datasets.speech_commands_dataset import *\n","from transforms import transforms_wav as twav\n","from transforms import transforms_stft as tstft\n","from mixup import *"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":228,"status":"ok","timestamp":1711203760900,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"Ej4vv6N2yQ9s"},"outputs":[],"source":["### Parametros del script\n","from collections import namedtuple\n","\n","Args = namedtuple('Args', [\n","    'train_dataset',\n","    'valid_dataset',\n","    'background_noise',\n","    'comment',\n","    'batch_size',\n","    'dataload_workers_nums',\n","    'weight_decay',\n","    'optim',\n","    'learning_rate',\n","    'lr_scheduler',\n","    'lr_scheduler_patience',\n","    'lr_scheduler_step_size',\n","    'lr_scheduler_gamma',\n","    'max_epochs',\n","    # 'resume',\n","    'model',\n","    'input',\n","    'mixup'\n","  ])\n","\n","args = Args(\n","    train_dataset='../data/classifier/train.csv',\n","    valid_dataset='../data/classifier/val.csv',\n","    background_noise='datasets/_background_noise_',\n","    comment='',\n","    batch_size=96,\n","    dataload_workers_nums=6,\n","    weight_decay=1e-3,\n","    optim='sgd',\n","    learning_rate=0.001,\n","    lr_scheduler='plateau',\n","    lr_scheduler_patience=5,\n","    lr_scheduler_step_size=50,\n","    lr_scheduler_gamma=0.1,\n","    max_epochs=70,\n","    # resume='',\n","    model='resnext29_8_64',\n","    input='mel32',\n","    mixup=False\n","    )"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1711203763117,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"BZjSZYzC1NL_","outputId":"ea0e92f5-74dd-428b-91ea-73ca613059d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["use_gpu False\n"]}],"source":["use_gpu = torch.cuda.is_available()\n","print('use_gpu', use_gpu)\n","if use_gpu:\n","    torch.backends.cudnn.benchmark = True\n","n_mels = 32"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1552,"status":"ok","timestamp":1711203765422,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"K_KFY_uy1b0g","outputId":"9a05d9a7-428f-4f4a-f357-e142ddda0f2f"},"outputs":[],"source":["data_aug_transform = Compose([\n","    twav.ChangeAmplitude(),\n","    twav.ChangeSpeedAndPitchAudio(),\n","    twav.FixAudioLength(),\n","    tstft.ToSTFT(),\n","    tstft.StretchAudioOnSTFT(),\n","    tstft.TimeshiftAudioOnSTFT(),\n","    tstft.FixSTFTDimension()])\n","bg_dataset = BackgroundNoiseDataset(args.background_noise, data_aug_transform)\n","add_bg_noise = tstft.AddBackgroundNoiseOnSTFT(bg_dataset)\n","train_feature_transform = Compose([\n","    tstft.ToMelSpectrogramFromSTFT(n_mels=n_mels),\n","    tstft.DeleteSTFT(),\n","    twav.ToTensor('mel_spectrogram', 'input')])\n","train_dataset = SpeechCommandsDataset(args.train_dataset,\n","                                Compose([twav.LoadAudio(),\n","                                         data_aug_transform,\n","                                         add_bg_noise,\n","                                         train_feature_transform]))\n","\n","valid_feature_transform = Compose([\n","    twav.ToMelSpectrogram(n_mels=n_mels),\n","    twav.ToTensor('mel_spectrogram', 'input')])\n","valid_dataset = SpeechCommandsDataset(args.valid_dataset,\n","                                Compose([twav.LoadAudio(),\n","                                         twav.FixAudioLength(),\n","                                         valid_feature_transform]))\n","\n","weights = train_dataset.make_weights_for_balanced_classes()\n","sampler = WeightedRandomSampler(weights, len(weights))\n","train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, sampler=sampler, drop_last=True)\n","                            #   pin_memory=use_gpu, num_workers=args.dataload_workers_nums)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False)\n","                            #   pin_memory=use_gpu, num_workers=args.dataload_workers_nums)\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","df_train = pd.read_csv(args.train_dataset)\n","df_val = pd.read_csv(args.valid_dataset)\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# np.sort?"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["array(['OTHER', 'BOAFAB'], dtype=object)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["np.flip(np.sort(df_val['class'].unique()))\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["array(['OTHER', 'BOAFAB'], dtype=object)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df_train['class'].unique()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["train = pd.DataFrame(train_dataset.data)\n","val = pd.DataFrame(valid_dataset.data)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2296</th>\n","      <td>../data/train_gen/BOAFAB/2642_18_FNJV_0032140_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2297</th>\n","      <td>../data/train_gen/BOAFAB/3770_87_FNJV_0011774_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2298</th>\n","      <td>../data/train_gen/BOAFAB/3359_86_FNJV_0030864_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2299</th>\n","      <td>../data/train_gen/BOAFAB/3468_32_FNJV_0030856_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2300</th>\n","      <td>../data/train_gen/BOAFAB/2323_96_FNJV_0032464_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4636</th>\n","      <td>../data/train_gen/BOAFAB/2618_92_FNJV_0032289_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4637</th>\n","      <td>../data/train_gen/BOAFAB/2367_40_FNJV_0032314_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4638</th>\n","      <td>../data/train_gen/BOAFAB/3426_63_FNJV_0030858_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4639</th>\n","      <td>../data/train_gen/BOAFAB/3943_22_FNJV_0011068_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4640</th>\n","      <td>../data/train_gen/BOAFAB/1489_47_FNJV_0040072_...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2345 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                      0  1\n","2296  ../data/train_gen/BOAFAB/2642_18_FNJV_0032140_...  1\n","2297  ../data/train_gen/BOAFAB/3770_87_FNJV_0011774_...  1\n","2298  ../data/train_gen/BOAFAB/3359_86_FNJV_0030864_...  1\n","2299  ../data/train_gen/BOAFAB/3468_32_FNJV_0030856_...  1\n","2300  ../data/train_gen/BOAFAB/2323_96_FNJV_0032464_...  1\n","...                                                 ... ..\n","4636  ../data/train_gen/BOAFAB/2618_92_FNJV_0032289_...  1\n","4637  ../data/train_gen/BOAFAB/2367_40_FNJV_0032314_...  1\n","4638  ../data/train_gen/BOAFAB/3426_63_FNJV_0030858_...  1\n","4639  ../data/train_gen/BOAFAB/3943_22_FNJV_0011068_...  1\n","4640  ../data/train_gen/BOAFAB/1489_47_FNJV_0040072_...  1\n","\n","[2345 rows x 2 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["val.loc[val[1] == 1]\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9181</th>\n","      <td>../data/train_gen/BOAFAB/3754_30_FNJV_0011775_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9182</th>\n","      <td>../data/train_gen/BOAFAB/3464_2_FNJV_0030856_B...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9183</th>\n","      <td>../data/train_gen/BOAFAB/3360_5_FNJV_0030864_B...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9184</th>\n","      <td>../data/train_gen/BOAFAB/2376_4_FNJV_0032314_B...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9185</th>\n","      <td>../data/train_gen/BOAFAB/2626_6_FNJV_0032289_B...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>18556</th>\n","      <td>../data/train_gen/BOAFAB/3921_83_FNJV_0011767_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18557</th>\n","      <td>../data/train_gen/BOAFAB/2370_11_FNJV_0032314_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18558</th>\n","      <td>../data/train_gen/BOAFAB/2648_90_FNJV_0032140_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18559</th>\n","      <td>../data/train_gen/BOAFAB/3755_48_FNJV_0011775_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18560</th>\n","      <td>../data/train_gen/BOAFAB/2332_89_FNJV_0032464_...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9380 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                       0  1\n","9181   ../data/train_gen/BOAFAB/3754_30_FNJV_0011775_...  1\n","9182   ../data/train_gen/BOAFAB/3464_2_FNJV_0030856_B...  1\n","9183   ../data/train_gen/BOAFAB/3360_5_FNJV_0030864_B...  1\n","9184   ../data/train_gen/BOAFAB/2376_4_FNJV_0032314_B...  1\n","9185   ../data/train_gen/BOAFAB/2626_6_FNJV_0032289_B...  1\n","...                                                  ... ..\n","18556  ../data/train_gen/BOAFAB/3921_83_FNJV_0011767_...  1\n","18557  ../data/train_gen/BOAFAB/2370_11_FNJV_0032314_...  1\n","18558  ../data/train_gen/BOAFAB/2648_90_FNJV_0032140_...  1\n","18559  ../data/train_gen/BOAFAB/3755_48_FNJV_0011775_...  1\n","18560  ../data/train_gen/BOAFAB/2332_89_FNJV_0032464_...  1\n","\n","[9380 rows x 2 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train.loc[train[1] == 1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# a name used to save checkpoints etc.\n","full_name = '%s_%s_%s_bs%d_lr%.1e_wd%.1e' % (args.model, args.optim, args.lr_scheduler, args.batch_size, args.learning_rate, args.weight_decay)\n","if args.comment:\n","    full_name = '%s_%s' % (full_name, args.comment)\n","\n","model = models.create_model(model_name=args.model, num_classes=len(train_dataset.classes), in_channels=1)\n","\n","if use_gpu:\n","    model = torch.nn.DataParallel(model).cuda()\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","if args.optim == 'sgd':\n","    optimizer = torch.optim.SGD(model.parameters(), lr=args.learning_rate, momentum=0.9, weight_decay=args.weight_decay)\n","else:\n","    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n","\n","start_timestamp = int(time.time()*1000)\n","start_epoch = 0\n","best_accuracy = 0\n","best_loss = 1e100\n","global_step = 0\n","\n","# if args.resume:\n","#     print(\"resuming a checkpoint '%s'\" % args.resume)\n","#     checkpoint = torch.load(args.resume)\n","#     model.load_state_dict(checkpoint['state_dict'])\n","#     model.float()\n","#     optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","#     best_accuracy = checkpoint.get('accuracy', best_accuracy)\n","#     best_loss = checkpoint.get('loss', best_loss)\n","#     start_epoch = checkpoint.get('epoch', start_epoch)\n","#     global_step = checkpoint.get('step', global_step)\n","\n","#     del checkpoint  # reduce memory\n","\n","if args.lr_scheduler == 'plateau':\n","    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=args.lr_scheduler_patience, factor=args.lr_scheduler_gamma)\n","else:\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_scheduler_step_size, gamma=args.lr_scheduler_gamma, last_epoch=start_epoch-1)\n","\n","def get_lr():\n","    return optimizer.param_groups[0]['lr']\n","\n","writer = SummaryWriter(comment=('_speech_commands_' + full_name))\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1711203766273,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"Z_sHL8jwsQHL","outputId":"b988f868-1079-4649-de9f-6984076e01d1"},"outputs":[{"data":{"text/plain":["0.001"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["get_lr()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1711203700125,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"KFocZJti6buZ","outputId":"3a7a0d12-6cee-48b6-c14a-4db3ee266c44"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["next(model.parameters()).device"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":263,"status":"ok","timestamp":1711203768063,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"nzBvg5UX235J"},"outputs":[],"source":["def train(epoch):\n","    global global_step\n","\n","    print(\"epoch %3d with lr=%.02e\" % (epoch, get_lr()))\n","    phase = 'train'\n","    writer.add_scalar('%s/learning_rate' % phase,  get_lr(), epoch)\n","\n","    model.train()  # Set model to training mode\n","\n","    running_loss = 0.0\n","    it = 0\n","    correct = 0\n","    total = 0\n","\n","    pbar = tqdm(train_dataloader, unit=\"audios\", unit_scale=train_dataloader.batch_size)\n","    for batch in pbar:\n","        inputs = batch['input']\n","        inputs = torch.unsqueeze(inputs, 1)\n","        targets = batch['target']\n","\n","        if args.mixup:\n","            inputs, targets = mixup(inputs, targets, num_classes=len(train_dataset.classes))\n","\n","        inputs = Variable(inputs, requires_grad=True)\n","        targets = Variable(targets, requires_grad=False)\n","\n","        if use_gpu:\n","            inputs = inputs.cuda()\n","            targets = targets.cuda()\n","\n","        # forward/backward\n","        outputs = model(inputs)\n","        if args.mixup:\n","            loss = mixup_cross_entropy_loss(outputs, targets)\n","        else:\n","            loss = criterion(outputs, targets)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # statistics\n","        it += 1\n","        global_step += 1\n","        # print(\"--------------------------------------------------------------------\", loss.data)\n","        running_loss += loss.data.item()\n","        pred = outputs.data.max(1, keepdim=True)[1]\n","        if args.mixup:\n","            targets = batch['target']\n","            targets = Variable(targets, requires_grad=False).cuda()\n","        correct += pred.eq(targets.data.view_as(pred)).sum()\n","        total += targets.size(0)\n","\n","        writer.add_scalar('%s/loss' % phase, loss.data.item(), global_step)\n","\n","        # update the progress bar\n","        pbar.set_postfix({\n","            'loss': \"%.05f\" % (running_loss / it),\n","            'acc': \"%.02f%%\" % (100*correct/total)\n","        })\n","\n","    accuracy = correct/total\n","    epoch_loss = running_loss / it\n","    writer.add_scalar('%s/accuracy' % phase, 100*accuracy, epoch)\n","    writer.add_scalar('%s/epoch_loss' % phase, epoch_loss, epoch)\n","\n","    return epoch_loss\n","\n","def valid(epoch):\n","    global best_accuracy, best_loss, global_step\n","\n","    phase = 'valid'\n","    model.eval()  # Set model to evaluate mode\n","\n","    running_loss = 0.0\n","    it = 0\n","    correct = 0\n","    total = 0\n","\n","    pbar = tqdm(valid_dataloader, unit=\"audios\", unit_scale=valid_dataloader.batch_size)\n","    for batch in pbar:\n","        inputs = batch['input']\n","        inputs = torch.unsqueeze(inputs, 1)\n","        targets = batch['target']\n","\n","        with torch.no_grad():\n","            inputs = Variable(inputs, volatile = True)\n","        targets = Variable(targets, requires_grad=False)\n","\n","        if use_gpu:\n","            inputs = inputs.cuda()\n","            targets = targets.cuda()\n","\n","        # forward\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        # statistics\n","        it += 1\n","        global_step += 1\n","        running_loss += loss.data.item()\n","        pred = outputs.data.max(1, keepdim=True)[1]\n","        correct += pred.eq(targets.data.view_as(pred)).sum()\n","        total += targets.size(0)\n","\n","        writer.add_scalar('%s/loss' % phase, loss.data.item(), global_step)\n","\n","        # update the progress bar\n","        pbar.set_postfix({\n","            'loss': \"%.05f\" % (running_loss / it),\n","            'acc': \"%.02f%%\" % (100*correct/total)\n","        })\n","\n","    accuracy = correct/total\n","    epoch_loss = running_loss / it\n","    writer.add_scalar('%s/accuracy' % phase, 100*accuracy, epoch)\n","    writer.add_scalar('%s/epoch_loss' % phase, epoch_loss, epoch)\n","\n","    checkpoint = {\n","        'epoch': epoch,\n","        'step': global_step,\n","        'state_dict': model.state_dict(),\n","        'loss': epoch_loss,\n","        'accuracy': accuracy,\n","        'optimizer' : optimizer.state_dict(),\n","    }\n","\n","    if accuracy > best_accuracy:\n","        best_accuracy = accuracy\n","        torch.save(checkpoint, 'checkpoints/best-loss-speech-commands-checkpoint-%s.pth' % full_name)\n","        torch.save(model, '%d-%s-best-loss.pth' % (start_timestamp, full_name))\n","    if epoch_loss < best_loss:\n","        best_loss = epoch_loss\n","        torch.save(checkpoint, 'checkpoints/best-acc-speech-commands-checkpoint-%s.pth' % full_name)\n","        torch.save(model, '%d-%s-best-acc.pth' % (start_timestamp, full_name))\n","\n","    torch.save(checkpoint, 'checkpoints/last-speech-commands-checkpoint.pth')\n","    del checkpoint  # reduce memory\n","\n","    return epoch_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgXnF02D26kN","outputId":"024dabd7-baa9-4100-b1ef-c5da00bf96d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["training resnext29_8_64 for Google speech commands...\n","epoch   0 with lr=1.00e-03\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 18528/18528 [06:21<00:00, 48.56audios/s, loss=0.41497, acc=79.31%]\n","  0%|          | 0/4704 [00:00<?, ?audios/s]<ipython-input-18-448e3ae6f1f5>:86: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  inputs = Variable(inputs, volatile = True)\n","100%|██████████| 4704/4704 [00:44<00:00, 105.88audios/s, loss=5.66779, acc=1.03%]\n"]},{"name":"stdout","output_type":"stream","text":["total time elapsed: 0h 7m 11s , best accuracy: 1.03%, best loss 5.667788\n","epoch   1 with lr=1.00e-03\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 18528/18528 [06:15<00:00, 49.28audios/s, loss=0.20154, acc=90.76%]\n","100%|██████████| 4704/4704 [00:43<00:00, 108.95audios/s, loss=8.02428, acc=0.26%]\n"]},{"name":"stdout","output_type":"stream","text":["total time elapsed: 0h 14m 12s , best accuracy: 1.03%, best loss 5.667788\n","epoch   2 with lr=1.00e-03\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 18528/18528 [06:15<00:00, 49.28audios/s, loss=0.15133, acc=93.30%]\n","100%|██████████| 4704/4704 [00:42<00:00, 111.11audios/s, loss=8.84070, acc=0.26%]\n"]},{"name":"stdout","output_type":"stream","text":["total time elapsed: 0h 21m 11s , best accuracy: 1.03%, best loss 5.667788\n","epoch   3 with lr=1.00e-03\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 18528/18528 [06:14<00:00, 49.49audios/s, loss=0.12562, acc=94.27%]\n","100%|██████████| 4704/4704 [00:42<00:00, 110.49audios/s, loss=9.83417, acc=0.19%]\n"]},{"name":"stdout","output_type":"stream","text":["total time elapsed: 0h 28m 9s , best accuracy: 1.03%, best loss 5.667788\n","epoch   4 with lr=1.00e-03\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 6048/18528 [02:03<04:10, 49.73audios/s, loss=0.11695, acc=94.51%]"]}],"source":["print(\"training %s for Google speech commands...\" % args.model)\n","since = time.time()\n","for epoch in range(start_epoch, args.max_epochs):\n","    if args.lr_scheduler == 'step':\n","        lr_scheduler.step()\n","\n","    train(epoch)\n","    epoch_loss = valid(epoch)\n","\n","    if args.lr_scheduler == 'plateau':\n","        lr_scheduler.step(metrics=epoch_loss)\n","\n","    time_elapsed = time.time() - since\n","    time_str = 'total time elapsed: {:.0f}h {:.0f}m {:.0f}s '.format(time_elapsed // 3600, time_elapsed % 3600 // 60, time_elapsed % 60)\n","    print(\"%s, best accuracy: %.02f%%, best loss %f\" % (time_str, 100*best_accuracy, best_loss))\n","print(\"finished\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710898506254,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"ccYZuik32Buc","outputId":"5a1e1808-ac6d-4ce1-d71b-beaa44be0913"},"outputs":[{"name":"stdout","output_type":"stream","text":["python3: can't open file '/content/train_speech_commands.py': [Errno 2] No such file or directory\n"]}],"source":["# !python train_speech_commands.py --model=resnext29_8_64 --optim=sgd --lr-scheduler=plateau --learning-rate=0.01 --lr-scheduler-patience=5 --max-epochs=70 --batch-size=1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95328,"status":"ok","timestamp":1711136992267,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"9mwY3-um2wvU","outputId":"73cacd71-5714-4aed-a366-eb3d69dd3f14"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.0)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Collecting torchnet\n","  Downloading torchnet-0.0.4.tar.gz (23 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchnet) (2.2.1+cu121)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchnet) (1.16.0)\n","Collecting visdom (from torchnet)\n","  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchnet)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchnet)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchnet)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchnet)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchnet)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchnet)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->torchnet)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchnet)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchnet)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->torchnet)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->torchnet)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchnet)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (1.11.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (2.31.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (6.3.3)\n","Collecting jsonpatch (from visdom->torchnet)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (1.7.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchnet) (2.1.5)\n","Collecting jsonpointer>=1.9 (from jsonpatch->visdom->torchnet)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->torchnet) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->torchnet) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->torchnet) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->torchnet) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchnet) (1.3.0)\n","Building wheels for collected packages: torchnet, visdom\n","  Building wheel for torchnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchnet: filename=torchnet-0.0.4-py3-none-any.whl size=29727 sha256=6a4a86564b9fcc4599f4cc60bbd5a02cdee14d778bbf568507c06a7e2cb2d8ea\n","  Stored in directory: /root/.cache/pip/wheels/f7/ae/94/9f5edd6871983f30967ad11d60ef434c3d1b007654de4c8065\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=647dd6b4cc5339c670ca79bb36aa98cb4a1bc824e033f8254d716cd94de64706\n","  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n","Successfully built torchnet visdom\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jsonpointer, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jsonpatch, visdom, nvidia-cusolver-cu12, torchnet\n","Successfully installed jsonpatch-1.33 jsonpointer-2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 torchnet-0.0.4 visdom-0.2.4\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20886,"status":"ok","timestamp":1711136849321,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"NHB8eF0S2b9b","outputId":"4495ddf5-a283-474c-c346-9b5d05f24f12"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":489,"status":"ok","timestamp":1710898610500,"user":{"displayName":"Sebastian","userId":"01548533666923454856"},"user_tz":300},"id":"OCL9uamn3Kxe","outputId":"246c5adc-cd1e-47d4-bc7f-33646838a881"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Tesis/tesis/classificador\n"]}],"source":["cd \"drive/MyDrive/Tesis/tesis/classificador\""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
